{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Image.open(\"data/test/paper/color3.jpg\").convert(\"L\")\n",
    "img.save(\"data/test/paper/color3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vgg = Discriminator().to(device)\n",
    "summary(vgg, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.Generators import Generator,Generator_Mod,Generator2\n",
    "from core.Discriminator import Discriminator,Discriminator_Mod\n",
    "from Gan_train import Gray_GanTrainer\n",
    "from config import CycleGANConfig as config\n",
    "from core.data_loader import DefaultDataset,get_test_loader,get_gray_test_loader\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import torchvision\n",
    "import argparse\n",
    "import torchvision.utils as tvutils\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from Gan_main import main\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Resize([256,256])\n",
    "                              ])\n",
    "dataset=DefaultDataset('./data/test',transform=transform)\n",
    "loader=data.DataLoader(dataset=dataset,batch_size=8)\n",
    "torch_to_image = transforms.Compose([\n",
    "    transforms.Normalize(mean=(-1, -1, -1), std=(2, 2, 2)),  # [-1, 1] to [0, 1]\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "for img in loader:\n",
    "  plt.axis('off')\n",
    "  plt.imshow(torchvision.utils.make_grid(img,nrow=4,padding=5,pad_value=0.0,normalize=True).permute(1,2,0))\n",
    "  plt.savefig(\"test\",dpi=500)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch running with device cuda\n",
      "Preparing DataLoader for the generation phase...\n"
     ]
    }
   ],
   "source": [
    "# 생성된 이미지 원하는데에 저장 for fid\n",
    "torch_to_image = transforms.Compose([\n",
    "    transforms.Normalize(mean=(-1, -1, -1), std=(2, 2, 2)),  # [-1, 1] to [0, 1]\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "device=config.device\n",
    "print(\"PyTorch running with device {0}\".format(device))\n",
    "G = Generator_Mod().to(device)\n",
    "\n",
    "checkpoint=torch.load(\"checkpoints/CycleGAN/Mod/cartoonization/checkpoint-epoch-100.ckpt\")\n",
    "G.load_state_dict(checkpoint['G_state_dict'])\n",
    "\n",
    "test_images=get_test_loader(root=\"data/l\", batch_size=2, shuffle=False)\n",
    "ix=0\n",
    "G.eval()\n",
    "\n",
    "for img,label in test_images:\n",
    "    img=img.to(device)\n",
    "    img=G(img).detach().cpu()\n",
    "    for i in range(len(img)):\n",
    "        image=torch_to_image(img[i])\n",
    "        image.save(os.path.join(\"data/test/for_Mod_Cartoonizing\",'{0}.jpg'.format(ix)))\n",
    "        ix+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch running with device cuda\n",
      "Preparing DataLoader for the generation phase...\n"
     ]
    }
   ],
   "source": [
    "# 생성된 이미지 원하는데에 저장 for fid\n",
    "torch_to_image = transforms.Compose([\n",
    "    transforms.Normalize(mean=(-1, -1, -1), std=(2, 2, 2)),  # [-1, 1] to [0, 1]\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "device=config.device\n",
    "print(\"PyTorch running with device {0}\".format(device))\n",
    "G = Generator_Mod().to(device)\n",
    "\n",
    "checkpoint=torch.load(\"checkpoints/CycleGAN/Mod/cartoonization/checkpoint-epoch-100.ckpt\")\n",
    "G.load_state_dict(checkpoint['G_state_dict'])\n",
    "\n",
    "test_images=get_test_loader(root=\"data/test/for_add_experiment/data/cartoon\", batch_size=3, shuffle=False)\n",
    "ix=0\n",
    "G.eval()\n",
    "\n",
    "for img in test_images:\n",
    "    img=img.to(device)\n",
    "    mod_img=transforms.Resize(64)(img)\n",
    "    mod_img=nn.ZeroPad2d(96)(mod_img)\n",
    "    img=G(img).detach().cpu()\n",
    "    mod_generated_img=G(mod_img).detach().cpu()\n",
    "    mod_img.detach().cpu()\n",
    "    for image,mod_image in zip(img,mod_generated_img):\n",
    "        mod_image=torch_to_image(mod_image)\n",
    "        mod_image.save(os.path.join(\"data/test/for_add_experiment/transformed_data/cartoon/center_{0}.jpg\".format(ix)))\n",
    "        image=torch_to_image(image)\n",
    "        image.save(os.path.join(\"data/test/for_add_experiment/result/cartoon/center_{0}.jpg\".format(ix)))\n",
    "        ix+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc4bfa6772543d6073f3fd1028986b644e081e8ab7bbf491a79dc89050113a24"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('jaepoong')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
